{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vByijN-ih9W7",
        "outputId": "ba1283b8-56b8-4866-a296-886a1a1b62e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEl_itSiirgU"
      },
      "outputs": [],
      "source": [
        "!unzip 'drive/MyDrive/food11'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaD3A_TM5xVw"
      },
      "outputs": [],
      "source": [
        "import imageio   \n",
        "import os       \n",
        "import glob       \n",
        "from collections import Counter  \n",
        "import random \n",
        "myseed = 12345 \n",
        "\n",
        "from google.colab.patches import cv2_imshow  #display an image\n",
        "\n",
        "\n",
        "# let's take a look at one random image \n",
        "random_pic_file = random.choice(os.listdir('./food11/validation/'))\n",
        "pic = imageio.imread('./food11/training/'+ random_pic_file)   #eads the image data\n",
        "cv2_imshow(pic)   #shows the image in the output.\n",
        "height, width, channels = pic.shape  #xtracts the height, width, and number of channels (color components) of the image\n",
        "print(f'original height, width, and channels of each image: {height} {width} {channels}')\n",
        "\n",
        "# let's take a look at label distirbution \n",
        "folder_path_options = [\"./food11/training/\", \"./food11/test/\", \"./food11/validation/\"]  #the paths of three directories: training, test, and validation.\n",
        "for path in folder_path_options:\n",
        "  labels = []\n",
        " \n",
        "  files = glob.glob(path+\"*\")   \n",
        "\n",
        "  \n",
        "  if \"test\" in path:\n",
        "    continue\n",
        "  \n",
        "  labels = [int(filename[len(path):].split(\"_\")[0]) for filename in files]\n",
        " \n",
        "  counts = Counter(labels)\n",
        "  total_count = len(labels)\n",
        "  for value, count in sorted(counts.items(), key=lambda x: x[0]):\n",
        "    distribution = count / total_count\n",
        "    print(f'{value}: {count} ({distribution:.2%})')                     \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOkkotLpg4Dt"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch   \n",
        "import os\n",
        "import torch.nn as nn   #resizing, cropping, and normalization.\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image   \n",
        "\n",
        "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset  \n",
        "#These classes and functions are used for handling datasets and creating data loaders in PyTorch.\n",
        "from torchvision.datasets import DatasetFolder, VisionDataset\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbaJvHMrhTzs"
      },
      "outputs": [],
      "source": [
        "# basic setup for PyTorch\n",
        "torch.backends.cudnn.deterministic = True    #flag of the cuDNN backend in PyTorch\n",
        "torch.backends.cudnn.benchmark = False  \n",
        "\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s755H_WhcUy"
      },
      "outputs": [],
      "source": [
        "## All we need here is to resize the PIL image and transform it into Tensor.\n",
        "train_tfm = transforms.Compose([\n",
        "    # Resize the image into a fixed shape (height = width = 128)\n",
        "    transforms.Resize((128, 128)),\n",
        "    \n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_tfm = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OODePXcgZGUB"
      },
      "outputs": [],
      "source": [
        "class FoodDataset(Dataset):  #extends the functionality of the base Dataset class in PyTorch.\n",
        "    def __init__(self,path,tfm=test_tfm,files = None):\n",
        "      \n",
        "        super(FoodDataset).__init__()\n",
        "        self.path = path\n",
        "        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
        "        \n",
        "        if files != None:\n",
        "            self.files = files\n",
        "        print(f\"One {path} sample\",self.files[0]) \n",
        "        self.transform = tfm\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "  \n",
        "    def __getitem__(self,idx):\n",
        "        fname = self.files[idx]  #This line retrieves the file path at the given index idx \n",
        "        im = Image.open(fname) \n",
        "        im = self.transform(im)\n",
        "  \n",
        "        try:\n",
        "            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n",
        "            \n",
        "        except:\n",
        "            label = -1 # test has no label\n",
        "        return im,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhjxMvpmOeKG"
      },
      "outputs": [],
      "source": [
        "class FirstCNN(nn.Module):  \n",
        "    def __init__(self):  \n",
        "        super(FirstCNN, self).__init__() #calls parent class (nn.Module) to ensure that the necessary initialization steps are performed.\n",
        "       \n",
        "        \n",
        "        self.cnn = nn.Sequential(  \n",
        "            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
        "\n",
        "            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
        "            \n",
        "            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
        "        )\n",
        "\n",
        "      \n",
        "        self.fc = nn.Sequential(  \n",
        "            nn.Linear(512*4*4, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 11)\n",
        "        )\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "      \n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1) \n",
        "        \n",
        "        return self.fc(out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVHDesVtjDV6"
      },
      "source": [
        "# Load training and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liffixwXPHod",
        "outputId": "4713fec7-79a2-4c71-a3cf-dac945896d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One ./food11/training sample ./food11/training/0_0.jpg\n",
            "One ./food11/validation sample ./food11/validation/0_0.jpg\n"
          ]
        }
      ],
      "source": [
        "_exp_name = \"sample\"\n",
        "batch_size = 64\n",
        "_dataset_dir = \"./food11\"\n",
        "# Construct datasets.\n",
        "# The argument \"loader\" tells how torchvision reads the data.\n",
        "train_set = FoodDataset(os.path.join(_dataset_dir,\"training\"), tfm=train_tfm)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "valid_set = FoodDataset(os.path.join(_dataset_dir,\"validation\"), tfm=test_tfm)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WO9GAkDjKcJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "n_epochs = 4\n",
        "patience = 300 \n",
        "model = FirstCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5) \n",
        "stale = 0\n",
        "best_acc = 0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "   \n",
        "    train_loss = []\n",
        "    train_accs = []\n",
        "\n",
        "    for batch in tqdm(train_loader):\n",
        "\n",
        "        # A batch consists of image data and corresponding labels.\n",
        "        imgs, labels = batch\n",
        "        logits = model(imgs.to(device))\n",
        "        loss = criterion(logits, labels.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
        "\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        \n",
        "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
        "\n",
        "        # Record the loss and accuracy.\n",
        "        train_loss.append(loss.item())\n",
        "        train_accs.append(acc)\n",
        "        \n",
        "    train_loss = sum(train_loss) / len(train_loss)\n",
        "    train_acc = sum(train_accs) / len(train_accs)\n",
        "\n",
        "    # Print the information.\n",
        "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    # These are used to record information in validation.\n",
        "    valid_loss = []\n",
        "    valid_accs = []\n",
        "\n",
        "    # Iterate the validation set by batches.\n",
        "    for batch in tqdm(valid_loader):\n",
        "\n",
        "        # A batch consists of image data and corresponding labels.\n",
        "        imgs, labels = batch\n",
        "        #imgs = imgs.half()\n",
        "\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            logits = model(imgs.to(device))\n",
        "\n",
        "        # We can still compute the loss (but not the gradient).\n",
        "        loss = criterion(logits, labels.to(device))\n",
        "\n",
        "        # Compute the accuracy for current batch.\n",
        "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
        "\n",
        "        # Record the loss and accuracy.\n",
        "        valid_loss.append(loss.item())\n",
        "        valid_accs.append(acc)\n",
        "        #break\n",
        "\n",
        "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
        "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
        "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
        "\n",
        "    # Print the information.\n",
        "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
        "\n",
        "\n",
        "    # update logs\n",
        "    if valid_acc > best_acc:\n",
        "        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
        "            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n",
        "    else:\n",
        "        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
        "            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
        "\n",
        "\n",
        "    # save models\n",
        "    if valid_acc > best_acc:\n",
        "        print(f\"Best model found at epoch {epoch}, saving model\")\n",
        "        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n",
        "        best_acc = valid_acc\n",
        "        stale = 0\n",
        "    else:\n",
        "        stale += 1\n",
        "        if stale > patience:\n",
        "            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPd8R3sroK_L"
      },
      "source": [
        "# Apply the best model on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lhy3C2GdoFX8"
      },
      "outputs": [],
      "source": [
        "# # set up test data loader\n",
        "# test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\n",
        "# test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "# model_best = FirstCNN().to(device)\n",
        "# model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n",
        "# model_best.eval()\n",
        "# prediction = []\n",
        "# with torch.no_grad():\n",
        "#     for data,_ in test_loader:\n",
        "#         test_pred = model_best(data.to(device))\n",
        "#         test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
        "#         prediction += test_label.squeeze().tolist()\n",
        "  \n",
        "# #create test csv\n",
        "# def pad4(i):\n",
        "#     return \"0\"*(4-len(str(i)))+str(i)\n",
        "# df = pd.DataFrame()\n",
        "# df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n",
        "# df[\"Category\"] = prediction\n",
        "# df.to_csv(\"test_prediction.csv\",index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMuF0FyUrb6T"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# set up test data loader\n",
        "test_set = FoodDataset(os.path.join(_dataset_dir, \"test\"), tfm=test_tfm)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "model_best = FirstCNN().to(device)\n",
        "model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n",
        "model_best.eval()\n",
        "\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for data, _ in test_loader:\n",
        "        test_pred = model_best(data.to(device))\n",
        "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
        "        predictions.extend(test_label.squeeze().tolist())\n",
        "\n",
        "# Print predicted labels and display corresponding images\n",
        "for i, prediction in enumerate(predictions):\n",
        "    image, _ = test_set[i]\n",
        "    plt.imshow(image.permute(1, 2, 0))\n",
        "    plt.title(f\"Predicted Label: {prediction}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}